{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML_HW4_Task3_as5961_mt3390.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZBB65ga2EB_",
        "colab_type": "text"
      },
      "source": [
        "**Applied Machine Learning - Homework 4 - Task3**\n",
        "\n",
        "Amaury Sudrie (UNI: AS5961)\n",
        "Maxime Tchibozo (UNI: MT3390)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "764AdbtW1_-7",
        "colab_type": "code",
        "outputId": "d090130a-fa74-4fbc-d03d-8db69fa0dd3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/AML/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bba3usv72Ryh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "#from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UARu0YgC2TrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('winemag-data-130k-v2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xI7DZsn2UVl",
        "colab_type": "code",
        "outputId": "6058f074-700c-4be9-d2ef-3af8789f5697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>country</th>\n",
              "      <th>description</th>\n",
              "      <th>designation</th>\n",
              "      <th>points</th>\n",
              "      <th>price</th>\n",
              "      <th>province</th>\n",
              "      <th>region_1</th>\n",
              "      <th>region_2</th>\n",
              "      <th>taster_name</th>\n",
              "      <th>taster_twitter_handle</th>\n",
              "      <th>title</th>\n",
              "      <th>variety</th>\n",
              "      <th>winery</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Italy</td>\n",
              "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
              "      <td>Vulkà Bianco</td>\n",
              "      <td>87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sicily &amp; Sardinia</td>\n",
              "      <td>Etna</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kerin O’Keefe</td>\n",
              "      <td>@kerinokeefe</td>\n",
              "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
              "      <td>White Blend</td>\n",
              "      <td>Nicosia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
              "      <td>Avidagos</td>\n",
              "      <td>87</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Douro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Roger Voss</td>\n",
              "      <td>@vossroger</td>\n",
              "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
              "      <td>Portuguese Red</td>\n",
              "      <td>Quinta dos Avidagos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>US</td>\n",
              "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Paul Gregutt</td>\n",
              "      <td>@paulgwine</td>\n",
              "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
              "      <td>Pinot Gris</td>\n",
              "      <td>Rainstorm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>US</td>\n",
              "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
              "      <td>Reserve Late Harvest</td>\n",
              "      <td>87</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>Lake Michigan Shore</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alexander Peartree</td>\n",
              "      <td>NaN</td>\n",
              "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
              "      <td>Riesling</td>\n",
              "      <td>St. Julian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>US</td>\n",
              "      <td>Much like the regular bottling from 2012, this...</td>\n",
              "      <td>Vintner's Reserve Wild Child Block</td>\n",
              "      <td>87</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Paul Gregutt</td>\n",
              "      <td>@paulgwine</td>\n",
              "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
              "      <td>Pinot Noir</td>\n",
              "      <td>Sweet Cheeks</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   country  ...         variety               winery\n",
              "0           0     Italy  ...     White Blend              Nicosia\n",
              "1           1  Portugal  ...  Portuguese Red  Quinta dos Avidagos\n",
              "2           2        US  ...      Pinot Gris            Rainstorm\n",
              "3           3        US  ...        Riesling           St. Julian\n",
              "4           4        US  ...      Pinot Noir         Sweet Cheeks\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei9ec_7OWZSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(columns=\"Unnamed: 0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewSYyO_ZirtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[['description','designation','title']] = df[['description','designation','title']].fillna('missing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hHpnPfm3-d0",
        "colab_type": "text"
      },
      "source": [
        "## **Question 3.1**\n",
        "Fine-tune a BERT model on the text data alone using the transformers library. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xktG7MlK8NO",
        "colab_type": "text"
      },
      "source": [
        "Due to the high memory and computational cost of Bert transformer embedding, we will only encode two of the three text features : **description** and **title**, and see if those embeddings are sufficient to obtain a good score with a Linear Regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzgawHPG4BAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV4yNetjHWuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install category_encoders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOCR37oo4M4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertModel, BertTokenizer, BertConfig, pipeline\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "from category_encoders.target_encoder import TargetEncoder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2rE2jIf4x0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "config = BertConfig(\n",
        "    hidden_size=128, \n",
        "    num_hidden_layers=6, \n",
        "    num_attention_heads=6).from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWR0MjDl41km",
        "colab_type": "code",
        "outputId": "91260db1-a3b6-4f4f-d243-e06bab739d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = df.drop(columns=\"points\"),df[\"points\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "\n",
        "#X_train, y_train = X_train.iloc[::3], y_train.iloc[::3]\n",
        "print(np.shape(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(97478, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfp5Vz2M5S_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = pipeline(task=\"feature-extraction\",\n",
        "               model=model,\n",
        "               tokenizer=tokenizer,\n",
        "               device=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvYAPmbvCLKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import time\n",
        "BERT = []\n",
        "new_train_vect = []\n",
        "count = 1\n",
        "\n",
        "for t in X_train['description']:\n",
        "  #tx = time.time()\n",
        "  BERT.append( np.array(nlp(t))[0,0] )\n",
        "  if count%1000 == 0:\n",
        "    new_train_vect.append( np.vstack(BERT) )\n",
        "    del(BERT)\n",
        "    BERT = []\n",
        "\n",
        "  count += 1\n",
        "  #print(time.time()-tx)\n",
        "\n",
        "\n",
        "new_train_vect.append(BERT)\n",
        "del(BERT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtpt9RLm5qSi",
        "colab_type": "code",
        "outputId": "0f90a415-af8d-45c6-d894-a418f26d5737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_train = np.vstack(new_train_vect)\n",
        "new_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97478, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZrTiBfRLoj8",
        "colab_type": "text"
      },
      "source": [
        "We first fit a Linear Regression model using only the **description** component. Bert has embedded the **description** of each row as a vector with 768 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVfr7Hc6oh15",
        "colab_type": "code",
        "outputId": "c236505d-fed3-4f4a-d69c-7b04be2fcb30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_LR = LinearRegression()\n",
        "\n",
        "scores = cross_val_score(model_LR, new_train, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))\n",
        "#model_LR.fit(new_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.5960626179210056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqzXqhUBMUwS",
        "colab_type": "text"
      },
      "source": [
        "Using **description** alone with Bert embedding yields a better score than using **description**,**title** and **designation** together with word2vec embedding (sccore of 56%). We will further improve upon this model by also considering **title**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-JerjuFZF_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import time\n",
        "BERT = []\n",
        "new_train_vect2 = []\n",
        "count = 1\n",
        "\n",
        "for t in X_train['title']:\n",
        "  #tx = time.time()\n",
        "  BERT.append( np.array(nlp(t))[0,0] )\n",
        "  if count%1000 == 0:\n",
        "    new_train_vect2.append( np.vstack(BERT) )\n",
        "    del(BERT)\n",
        "    BERT = []\n",
        "\n",
        "  count += 1\n",
        "  #print(time.time()-tx)\n",
        "\n",
        "\n",
        "new_train_vect2.append(BERT)\n",
        "del(BERT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEjEFtvaz1Zz",
        "colab_type": "code",
        "outputId": "5fe1fcbf-496b-4092-d247-f8d84d3d66c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_train2 = np.hstack( [np.vstack(new_train_vect2), new_train] )\n",
        "new_train2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97478, 1536)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxwij0dq0dam",
        "colab_type": "code",
        "outputId": "a36eb8c3-712f-418b-c2d3-2599cf214562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_LR = LinearRegression()\n",
        "\n",
        "scores = cross_val_score(model_LR, new_train2, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))\n",
        "#model_LR.fit(new_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.6429778134483181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFbuTrj3OwZA",
        "colab_type": "text"
      },
      "source": [
        "A Linear Regression model using Bert embedding for **description** and **title** yields a similar score to a ridge model with Bag of Words embedding using Tf-idf (score was 68%). However, the Bert-embedded vectors have shape (,1536), whereas the Tf-idf vectors had size (,4000). Since Linear Regression and Ridge usually perform better when we increase the number of features (so long as those features are not colinear), this means that the Bert embedded vectors contain much more information on the target than both word2vec vectors and Tf-idf with Bag of Word vectors. In other words, they contain more semantic information than the other methods (i.e information relative to the ordering of the words)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBBSBcGJB8oD",
        "colab_type": "text"
      },
      "source": [
        "## **Question 3.2**\n",
        "How does this model compare to a BoW model, and how does it compare to a model using all features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-DbRcQ6DUxH",
        "colab_type": "text"
      },
      "source": [
        "First let us have a look on the Bag of Word only while considering only the **title** and **description** features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIM9SpRfCRLL",
        "colab_type": "code",
        "outputId": "671864b0-4234-404e-ea1b-22bcf245c0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vect1 = make_pipeline(CountVectorizer(min_df=2, max_features=2000))\n",
        "vect2 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95))\n",
        "\n",
        "BoW_train = sp.sparse.hstack([\n",
        "    vect1.fit_transform(X_train[\"description\"]),\n",
        "    vect2.fit_transform(X_train[\"title\"]),\n",
        "])\n",
        "\n",
        "LR = LinearRegression()\n",
        "scores = cross_val_score(LR, BoW_train, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.7142438999014576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLeLJK-HDaxW",
        "colab_type": "text"
      },
      "source": [
        "Now let us compare to the complete model with all features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b1YHyGFCs5w",
        "colab_type": "code",
        "outputId": "589bae97-00b3-4995-c430-1341ccbe10a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cont = [\"price\"]\n",
        "cat_TE = [\"province\", \"region_1\", \"variety\", \"winery\"]\n",
        "cat_OHE = [\"country\", \"region_2\", \"taster_name\", \"taster_twitter_handle\"]\n",
        "\n",
        "X_train[cat_OHE + cat_TE] = X_train[cat_OHE + cat_TE].fillna('missing')\n",
        "Cont_Imputer = SimpleImputer(strategy='median')\n",
        "X_train[cont] = Cont_Imputer.fit_transform(X_train[cont])\n",
        "\n",
        "tfidf1 = make_pipeline(CountVectorizer(min_df=2, max_features=2000), TfidfTransformer())\n",
        "tfidf2 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95), TfidfTransformer())\n",
        "tfidf3 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95), TfidfTransformer())\n",
        "preprocess = make_column_transformer(\n",
        "    (TargetEncoder(), cat_TE),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), cat_OHE),\n",
        "    (StandardScaler(), cont)\n",
        ")\n",
        "\n",
        "train_all_feature = sp.sparse.hstack([\n",
        "    tfidf1.fit_transform(X_train[\"description\"]),\n",
        "    tfidf2.fit_transform(X_train[\"designation\"]),\n",
        "    tfidf3.fit_transform(X_train[\"title\"]),\n",
        "    preprocess.fit_transform(X_train[cont + cat_OHE + cat_TE], y_train),\n",
        "])\n",
        "\n",
        "LR = LinearRegression()\n",
        "scores = cross_val_score(LR, train_all_feature, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.7781389248802411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcK9Gv4URDBT",
        "colab_type": "text"
      },
      "source": [
        "The Bag of Word models still yield a better score than our previous Bert model. However, there are some important caveats to take into account. The Bag-of-Words embedding model on the other hand has 4009 dimensions whereas the Bert model has 1536.\n",
        "Due to memory limits on Colab, we cannot use the third text feature : **designation**, but seeing how well Bert embedding performs without it, we should expect that a model using this feature embedded with Bert should have a comparable (if not better score) than our state of the art model which used Bag of words with Tf-idf (score of ~77%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0dBK9GT2ots",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}