{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML_HW4_Task1_as5961_mt3390.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwZBECq9ACF",
        "colab_type": "text"
      },
      "source": [
        "**Applied Machine Learning - Homework 4 - Task1**\n",
        "\n",
        "Amaury Sudrie (UNI: AS5961)\n",
        "Maxime Tchibozo (UNI: MT3390)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ifgyr8E7tow",
        "colab_type": "code",
        "outputId": "ae41dbd4-e103-4398-b1c5-8f5c41e7f183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/AML/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8FpqTXH9Kw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvrxEf1_9fxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('winemag-data-130k-v2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Brv00Ta9h9C",
        "colab_type": "code",
        "outputId": "3ba4e613-5ed1-4d48-dcf6-11e6b4f9483b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>country</th>\n",
              "      <th>description</th>\n",
              "      <th>designation</th>\n",
              "      <th>points</th>\n",
              "      <th>price</th>\n",
              "      <th>province</th>\n",
              "      <th>region_1</th>\n",
              "      <th>region_2</th>\n",
              "      <th>taster_name</th>\n",
              "      <th>taster_twitter_handle</th>\n",
              "      <th>title</th>\n",
              "      <th>variety</th>\n",
              "      <th>winery</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Italy</td>\n",
              "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
              "      <td>Vulkà Bianco</td>\n",
              "      <td>87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sicily &amp; Sardinia</td>\n",
              "      <td>Etna</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kerin O’Keefe</td>\n",
              "      <td>@kerinokeefe</td>\n",
              "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
              "      <td>White Blend</td>\n",
              "      <td>Nicosia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
              "      <td>Avidagos</td>\n",
              "      <td>87</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Douro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Roger Voss</td>\n",
              "      <td>@vossroger</td>\n",
              "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
              "      <td>Portuguese Red</td>\n",
              "      <td>Quinta dos Avidagos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>US</td>\n",
              "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Paul Gregutt</td>\n",
              "      <td>@paulgwine</td>\n",
              "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
              "      <td>Pinot Gris</td>\n",
              "      <td>Rainstorm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>US</td>\n",
              "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
              "      <td>Reserve Late Harvest</td>\n",
              "      <td>87</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>Lake Michigan Shore</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alexander Peartree</td>\n",
              "      <td>NaN</td>\n",
              "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
              "      <td>Riesling</td>\n",
              "      <td>St. Julian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>US</td>\n",
              "      <td>Much like the regular bottling from 2012, this...</td>\n",
              "      <td>Vintner's Reserve Wild Child Block</td>\n",
              "      <td>87</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Willamette Valley</td>\n",
              "      <td>Paul Gregutt</td>\n",
              "      <td>@paulgwine</td>\n",
              "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
              "      <td>Pinot Noir</td>\n",
              "      <td>Sweet Cheeks</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   country  ...         variety               winery\n",
              "0           0     Italy  ...     White Blend              Nicosia\n",
              "1           1  Portugal  ...  Portuguese Red  Quinta dos Avidagos\n",
              "2           2        US  ...      Pinot Gris            Rainstorm\n",
              "3           3        US  ...        Riesling           St. Julian\n",
              "4           4        US  ...      Pinot Noir         Sweet Cheeks\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz2uTygu_M8j",
        "colab_type": "text"
      },
      "source": [
        "## **Question 1.1**\n",
        "Create a baseline model for predicting wine quality using only non-text features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w22XDwy_2-3",
        "colab_type": "text"
      },
      "source": [
        "### **Data exploration**\n",
        "First let's have a look at the dataset. We can directly remove the column **Unamed 0:** as it is just duplicate of indexes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufH5-3S1-UQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(columns=\"Unnamed: 0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rvlbcC-Buh8",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look at the distribution of NA values in the dataset. We can see that except for **region_2** most features have an acceptable number of missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "einkAs1eA2NF",
        "colab_type": "code",
        "outputId": "a728900e-47ae-4e1c-a716-2c0da7ceb3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "percent_missing = df.isnull().sum() * 100 / len(df)\n",
        "percent_missing.reset_index().rename(columns={0:'feature',1:'percentage'}, inplace=True)\n",
        "percent_missing"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "country                   0.048472\n",
              "description               0.000000\n",
              "designation              28.825661\n",
              "points                    0.000000\n",
              "price                     6.921544\n",
              "province                  0.048472\n",
              "region_1                 16.347493\n",
              "region_2                 61.136715\n",
              "taster_name              20.192197\n",
              "taster_twitter_handle    24.015357\n",
              "title                     0.000000\n",
              "variety                   0.000769\n",
              "winery                    0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgHpsTgDFk3s",
        "colab_type": "text"
      },
      "source": [
        "Let's now have a look at unique values. Due to their high cardinality, we can immediately see that **description**, **designation** and **title** will be embedded using Bag of Words.\n",
        "\n",
        "We can see that **region_2** has only 18 distinct values. Even though it has 60% of missing values, we will keep it.\n",
        "\n",
        "As **points** and **price** do not contain many values we will not plot the histogram or perform an in-depth analysis of the distribution of these features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFBIQQhFBElw",
        "colab_type": "code",
        "outputId": "3a223a3a-adbd-442f-fdfe-a5d8d882a345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "for key in df.keys():\n",
        "  print(key, len(df[key].unique()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "country 44\n",
            "description 119955\n",
            "designation 37980\n",
            "points 21\n",
            "price 391\n",
            "province 426\n",
            "region_1 1230\n",
            "region_2 18\n",
            "taster_name 20\n",
            "taster_twitter_handle 16\n",
            "title 118840\n",
            "variety 708\n",
            "winery 16757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kbHhEekJcfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y = df.drop(['points'],axis=1),df['points']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCKV3hCQID-q",
        "colab_type": "text"
      },
      "source": [
        "### **Non-text Baseline Model**\n",
        "\n",
        "From the previous analysis we will represent:\n",
        "\n",
        "*   **price** and **points** as continuous variables\n",
        "*   Use Target Encoding for **region_1**, **province**, **winery** and **variety**\n",
        "*   Use One Hot Encoding for other categorical variables : **country**, **region_2**, **taster_name** and **taster_twitter_handle**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDHdWL92Jsn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIn4jVG0Joe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "from category_encoders.target_encoder import TargetEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiuQZg_4Jqgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sITJm-3zH2kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cont = [\"price\"]\n",
        "cat_TE = [\"province\", \"region_1\", \"variety\", \"winery\"]\n",
        "cat_OHE = [\"country\", \"region_2\", \"taster_name\", \"taster_twitter_handle\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2kwaDH9KVbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = X_train[cont + cat_OHE + cat_TE]\n",
        "X1[cat_OHE + cat_TE] = X1[cat_OHE + cat_TE].fillna('missing')\n",
        "Cont_Imputer = SimpleImputer(strategy='median')\n",
        "X1[cont] = Cont_Imputer.fit_transform(X1[cont])\n",
        "\n",
        "X1_test = X_test[cont + cat_OHE + cat_TE]\n",
        "X1_test[cat_OHE + cat_TE] = X1_test[cat_OHE + cat_TE].fillna('missing')\n",
        "X1_test[cont] = Cont_Imputer.transform(X1_test[cont])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC9v78daKn0y",
        "colab_type": "code",
        "outputId": "610a0f1d-01bb-43ec-d319-19b29cd20251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "preprocess = make_column_transformer(\n",
        "    (TargetEncoder(), cat_TE),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), cat_OHE),\n",
        "    (StandardScaler(), cont)\n",
        ")\n",
        "\n",
        "model_LR = make_pipeline(preprocess, LinearRegression())\n",
        "\n",
        "scores = cross_val_score(model_LR, X1, y_train)\n",
        "model_LR.fit(X1, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.43124434959959695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bblHfrhxKyOH",
        "colab_type": "code",
        "outputId": "cf62d4d8-f2a9-41b6-828e-fcce718297ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(\"Score on test\", model_LR.score(X1_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score on test 0.4357303949987641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__UnPgqwBIzJ",
        "colab_type": "text"
      },
      "source": [
        "We can see that a first very simple Linear Regression model using non-text features yields 43% accuracy on both the train and the test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K0KkuXwfIEV",
        "colab_type": "text"
      },
      "source": [
        "## **Question 1.2**\n",
        "Create a simple text-based model using a bag-of-words approach and a linear model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sejboNCihM0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_BoW = [\"description\", \"designation\", \"title\"]\n",
        "X2 = X_train[cat_BoW]\n",
        "X2 = X2.fillna('missing')\n",
        "\n",
        "X2_test = X_test[cat_BoW]\n",
        "X2_test = X2_test.fillna('missing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPNfwetmQXu",
        "colab_type": "code",
        "outputId": "ec3fed7c-6992-4ed2-fa13-cead5820ec14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "vect1 = CountVectorizer(min_df=2, max_features=2000)\n",
        "vect2 = CountVectorizer(min_df=2, max_features=1000, max_df=0.95)\n",
        "vect3 = CountVectorizer(min_df=2, max_features=1000, max_df=0.95)\n",
        "\n",
        "BoW_train = sp.sparse.hstack([\n",
        "    vect1.fit_transform(X2[\"description\"]),\n",
        "    vect2.fit_transform(X2[\"designation\"]),\n",
        "    vect3.fit_transform(X2[\"title\"]),  \n",
        "])\n",
        "\n",
        "BoW_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<97478x4000 sparse matrix of type '<class 'numpy.longlong'>'\n",
              "\twith 3755908 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpaDZ0OUMAMM",
        "colab_type": "code",
        "outputId": "232fa4d0-b586-4d87-90f9-7f08c7c7b035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "LR = LinearRegression()\n",
        "scores = cross_val_score(LR, BoW_train, y_train)\n",
        "LR.fit(BoW_train,y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.7185574489294385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMdj6btVWPEP",
        "colab_type": "code",
        "outputId": "bf97681b-95ad-4716-c55d-91b0282b457e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "BoW_test = sp.sparse.hstack([\n",
        "    vect1.transform(X2_test[\"description\"]),\n",
        "    vect2.transform(X2_test[\"designation\"]),\n",
        "    vect3.transform(X2_test[\"title\"]),  \n",
        "])\n",
        "\n",
        "print(\"Score on test\", LR.score(BoW_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score on test 0.7194413333623249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anW3lB7mcxY7",
        "colab_type": "text"
      },
      "source": [
        "We observe that the Bag of Word method on the text features performs much better than the Baseline model. We achieve 72% accuracy on both train and test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_0hiL_3WBlR",
        "colab_type": "text"
      },
      "source": [
        "## **Question 1.2.2**\n",
        "Try using n-grams, characters, tf-idf rescaling and possibly other ways to tune the BoW model. Be aware that you might need to adjust the (regularization of the) linear model for different feature sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmLRxBFIbOlu",
        "colab_type": "text"
      },
      "source": [
        "### **TF-IDF**\n",
        "First let's have a look at the Tf-idf process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwzaLlaqQ9oA",
        "colab": {}
      },
      "source": [
        "cat_BoW = [\"description\", \"designation\", \"title\"]\n",
        "X3 = X_train[cat_BoW]\n",
        "X3 = X3.fillna('missing')\n",
        "\n",
        "X3_test = X_test[cat_BoW]\n",
        "X3_test = X3_test.fillna('missing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuV0B-j8bwFU",
        "colab_type": "code",
        "outputId": "ed6ba65f-75df-4a45-87ff-2c56083f730d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tfidf1 = make_pipeline(CountVectorizer(min_df=2, max_features=2000), TfidfTransformer())\n",
        "tfidf2 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95), TfidfTransformer())\n",
        "tfidf3 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95), TfidfTransformer())\n",
        "\n",
        "BoW_train = sp.sparse.hstack([\n",
        "    tfidf1.fit_transform(X3[\"description\"]),\n",
        "    tfidf2.fit_transform(X3[\"designation\"]),\n",
        "    tfidf3.fit_transform(X3[\"title\"]),  \n",
        "])\n",
        "\n",
        "BoW_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<97478x4000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3755908 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81x2YKEI8faW",
        "colab_type": "code",
        "outputId": "e2afbc24-3aaf-4421-9584-a1f7bc71b446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BoW_sub, _, y_sub, _ = train_test_split(BoW_train, y_train, train_size=0.25)\n",
        "\n",
        "param_grid_LR = {'alpha': np.logspace(-2,1, num=20)}  \n",
        "\n",
        "grid_LR = GridSearchCV(Ridge(), param_grid_LR, cv=5, return_train_score=True)\n",
        "grid_LR.fit(BoW_sub, y_sub)\n",
        "print(\"Best mean cross-validation score for LR: {:.3f}\".format(grid_LR.best_score_))\n",
        "print(\"Best parameters: {}\".format(grid_LR.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best mean cross-validation score for LR: 0.682\n",
            "Best parameters: {'alpha': 1.1288378916846884}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH2CXR99cLxK",
        "colab_type": "code",
        "outputId": "b94925dd-10c5-4c87-c5ee-5978ac160681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR = Ridge(alpha=1.129)\n",
        "scores = cross_val_score(LR, BoW_train, y_train)\n",
        "LR.fit(BoW_train, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.7245366236556758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOr6fSal7xoj",
        "colab_type": "text"
      },
      "source": [
        "The Tfidf process with a Ridge Regression gives a slightly better result than the Bag of Word baseline we previously did. It is therefore an improvement we keep for the other methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjF04JgudPZU",
        "colab_type": "text"
      },
      "source": [
        "### **N-grams**\n",
        "We will now use Bag of words on N-grams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKSOeWAUcP9v",
        "colab_type": "code",
        "outputId": "66eda44b-585b-41fa-d2ec-b0b5550436ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "vect1 = make_pipeline(CountVectorizer(min_df=2, max_features=2000, ngram_range=(1,4)), TfidfTransformer())\n",
        "vect2 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95, ngram_range=(1,4)), TfidfTransformer())\n",
        "vect3 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95, ngram_range=(1,4)), TfidfTransformer())\n",
        "\n",
        "BoW_train = sp.sparse.hstack([\n",
        "    vect1.fit_transform(X3[\"description\"]),\n",
        "    vect2.fit_transform(X3[\"designation\"]),\n",
        "    vect3.fit_transform(X3[\"title\"]),  \n",
        "])\n",
        "\n",
        "BoW_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<97478x4000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 5012906 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1WgqkZcm1Mf",
        "colab_type": "code",
        "outputId": "02f88f62-7576-46d3-d048-5bf6daad7972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BoW_sub, _, y_sub, _ = train_test_split(BoW_train, y_train, train_size=0.25)\n",
        "\n",
        "param_grid_LR = {'alpha': np.logspace(-2,1, num=20)}  \n",
        "\n",
        "grid_LR = GridSearchCV(Ridge(), param_grid_LR, cv=5, return_train_score=True)\n",
        "grid_LR.fit(BoW_sub, y_sub)\n",
        "print(\"Best mean cross-validation score for LR: {:.3f}\".format(grid_LR.best_score_))\n",
        "print(\"Best parameters: {}\".format(grid_LR.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best mean cross-validation score for LR: 0.665\n",
            "Best parameters: {'alpha': 2.3357214690901213}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncVquDj7dloD",
        "colab_type": "code",
        "outputId": "ffb25f5c-d680-49f3-d211-50d1f396d8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR = Ridge(alpha=2.336)\n",
        "scores = cross_val_score(LR, BoW_train, y_train)\n",
        "LR.fit(BoW_train, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.6983278147144512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQc5N3Gf9BGG",
        "colab_type": "text"
      },
      "source": [
        "Using N-grams on words performs worse than classical Tfidf, we will therefore not keep this method for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncuuRRZIa39d",
        "colab_type": "text"
      },
      "source": [
        "### **Characters**\n",
        "Let's have a look at N-grams using characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE_BlcxOdof_",
        "colab_type": "code",
        "outputId": "f00de8b5-94d3-4e45-8c16-15beaf009f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "vect1 = make_pipeline(CountVectorizer(min_df=3, max_features=2000, max_df=0.95, ngram_range=(3,7), analyzer='char_wb'), TfidfTransformer())\n",
        "vect2 = make_pipeline(CountVectorizer(min_df=3, max_features=1000, max_df=0.95, ngram_range=(3,7), analyzer='char_wb'), TfidfTransformer())\n",
        "vect3 = make_pipeline(CountVectorizer(min_df=3, max_features=1000, max_df=0.95, ngram_range=(3,7), analyzer='char_wb'), TfidfTransformer())\n",
        "\n",
        "BoW_train = sp.sparse.hstack([\n",
        "    vect1.fit_transform(X3[\"description\"]),\n",
        "    vect2.fit_transform(X3[\"designation\"]),\n",
        "    vect3.fit_transform(X3[\"title\"]),  \n",
        "])\n",
        "\n",
        "BoW_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<97478x4000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 36321105 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwqEnNppqnYm",
        "colab_type": "code",
        "outputId": "e269fe24-bb4e-4c12-fa00-6c6975a748fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BoW_sub, _, y_sub, _ = train_test_split(BoW_train, y_train, train_size=0.25)\n",
        "\n",
        "param_grid_LR = {'alpha': np.logspace(-2,1, num=20)}  \n",
        "\n",
        "grid_LR = GridSearchCV(Ridge(), param_grid_LR, cv=5, return_train_score=True)\n",
        "grid_LR.fit(BoW_sub, y_sub)\n",
        "print(\"Best mean cross-validation score for LR: {:.3f}\".format(grid_LR.best_score_))\n",
        "print(\"Best parameters: {}\".format(grid_LR.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best mean cross-validation score for LR: 0.654\n",
            "Best parameters: {'alpha': 0.7847599703514611}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouaDXlMXa_gJ",
        "colab_type": "code",
        "outputId": "2b124fb9-115b-4764-9adf-bbe670e44254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR = Ridge(alpha=0.785)\n",
        "scores = cross_val_score(LR, BoW_train, y_train)\n",
        "LR.fit(BoW_train, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.6777995896672605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50wfOnSJ9MeA",
        "colab_type": "text"
      },
      "source": [
        "Using N-grams on characters performs similarly to N-grams on words. However, the characters perform worse than classical Tfidf. We will not use this method for further analysis.\n",
        "\n",
        "In conclusion, Using Tf-idf yields the best score out of the Bag of words embedding methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdMO_vXL9bBd",
        "colab_type": "text"
      },
      "source": [
        "## **Question 1.3**\n",
        "Combine the non-text features and the text features. How does adding those features improve upon just using bag-of-words?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwFrvTsmbesr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_BoW = [\"description\", \"designation\", \"title\"]\n",
        "cont = [\"price\"]\n",
        "cat_TE = [\"province\", \"region_1\", \"variety\", \"winery\"]\n",
        "cat_OHE = [\"country\", \"region_2\", \"taster_name\", \"taster_twitter_handle\"]\n",
        "\n",
        "X4 = X_train[cat_BoW + cont + cat_OHE + cat_TE]\n",
        "X4[cat_BoW + cat_OHE + cat_TE] = X4[cat_BoW + cat_OHE + cat_TE].fillna('missing')\n",
        "Cont_Imputer = SimpleImputer(strategy='median')\n",
        "X4[cont] = Cont_Imputer.fit_transform(X4[cont])\n",
        "\n",
        "X4_test = X_test[cat_BoW + cont + cat_OHE + cat_TE]\n",
        "X4_test[cat_BoW + cat_OHE + cat_TE] = X4_test[cat_BoW + cat_OHE + cat_TE].fillna('missing')\n",
        "X4_test[cont] = Cont_Imputer.transform(X4_test[cont])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es9HS_3f9tuS",
        "colab_type": "code",
        "outputId": "ecd73c84-bba6-4093-afa6-e6d74a155069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tfidf1 = make_pipeline(CountVectorizer(min_df=2, max_features=2000), TfidfTransformer())\n",
        "tfidf2 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95), TfidfTransformer())\n",
        "tfidf3 = make_pipeline(CountVectorizer(min_df=2, max_features=1000, max_df=0.95), TfidfTransformer())\n",
        "preprocess = make_column_transformer(\n",
        "    (TargetEncoder(), cat_TE),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), cat_OHE),\n",
        "    (StandardScaler(), cont)\n",
        ")\n",
        "\n",
        "new_train = sp.sparse.hstack([\n",
        "    tfidf1.fit_transform(X4[\"description\"]),\n",
        "    tfidf2.fit_transform(X4[\"designation\"]),\n",
        "    tfidf3.fit_transform(X4[\"title\"]),\n",
        "    preprocess.fit_transform(X4[cont + cat_OHE + cat_TE], y_train),\n",
        "])\n",
        "\n",
        "new_test = sp.sparse.hstack([\n",
        "    tfidf1.transform(X4_test[\"description\"]),\n",
        "    tfidf2.transform(X4_test[\"designation\"]),\n",
        "    tfidf3.transform(X4_test[\"title\"]),\n",
        "    preprocess.transform(X4_test[cont + cat_OHE + cat_TE]),\n",
        "])\n",
        "\n",
        "new_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<97478x4102 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 4633210 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQU-re0_Ozxo",
        "colab_type": "text"
      },
      "source": [
        "First we try a Ridge Regression on the combination looking for alpha by doing a grid search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78rXXvskJn1D",
        "colab_type": "code",
        "outputId": "0d6e04a3-c3ef-4bdb-b204-c247565c8959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "new_sub, _, y_sub, _ = train_test_split(new_train, y_train, train_size=0.35)\n",
        "\n",
        "param_grid_LR = {'alpha': np.logspace(-2,1, num=30)}  \n",
        "\n",
        "grid_LR = GridSearchCV(Ridge(), param_grid_LR, cv=5, return_train_score=True)\n",
        "grid_LR.fit(new_sub, y_sub)\n",
        "print(\"Best mean cross-validation score for LR: {:.3f}\".format(grid_LR.best_score_))\n",
        "print(\"Best parameters: {}\".format(grid_LR.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best mean cross-validation score for LR: 0.760\n",
            "Best parameters: {'alpha': 1.4873521072935119}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPk11runJ2pl",
        "colab_type": "code",
        "outputId": "564aca3d-54f1-4e22-a62e-5d7a38515472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR = Ridge(alpha=1.4873521072935119)\n",
        "\n",
        "scores = cross_val_score(LR, new_train, y_train)\n",
        "LR.fit(new_train, y_train)\n",
        "print(\"Score Ridge Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Ridge Regression 0.7785811478130501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSov51L-O-sh",
        "colab_type": "text"
      },
      "source": [
        "Combining text and non-text features with a Ridge model yields our best score yet. The score is better than the one we obtained using only BoW and Tfidf. Here we have almost 78% on the train dataset.\n",
        "<br>\n",
        "Nonetheless will compare this model to one using Linear Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F41iic8V_9UI",
        "colab_type": "code",
        "outputId": "61f32d40-99aa-41bc-aa3b-885c774e8227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_LR = LinearRegression()\n",
        "\n",
        "scores = cross_val_score(model_LR, new_train, y_train)\n",
        "model_LR.fit(new_train, y_train)\n",
        "print(\"Score Linear Regression\", np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score Linear Regression 0.7795396893657197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CW7Qt30KAUS",
        "colab_type": "code",
        "outputId": "9b793794-97e2-45bc-871c-637b998d7782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_LR.score(new_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7585818844504174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzzZiLHkPVSo",
        "colab_type": "text"
      },
      "source": [
        "The classical Linear Regression performs slightly better than the Ridge. We will keep it as our final model. In conclusion we achieved almost 78% on the train dataset and 76% on the test dataset by using Tf-idf Bag of words embedding on the text features and taking into account the non-text features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kap076JOU_1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}